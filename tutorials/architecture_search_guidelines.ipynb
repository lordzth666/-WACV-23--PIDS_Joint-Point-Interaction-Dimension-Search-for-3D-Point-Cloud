{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guide: Predictor-based Architecture Search in PIDS\n",
    "\n",
    "This is a guideline regarding the architecture search part in the PIDS paper. Note that for the sample stage of predictor-based NAS, it is the most efficient to run 1 search on a single GPU, and distribute the workload during the sample process.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your project folder as follows. The working directory should be the same as the project folder. \n",
    "import os\n",
    "os.chdir(\"../..\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We upload the dataset to dropbox. You can download the related runtime via the links below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://duke.box.com/s/dajlest7kwcla1syqio0dma7rk284s3k"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-compile CPP wrappers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is better to re-run the compliation to build the CPP wrappers based on local kernel. You should run the shell under `pids_core/cpp_wrappers` under `pids_core/cpp_wrappers`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Stage\n",
    "A lot of architectures are sampled to get ready for the predictor training. You may need ~2K samples to train a sufficiently good predictor (~2*8 V100s)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Architecture-Performance Pairs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Architecture Search on SemanticKITTI (Sample Stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!CUDA_VISIBLE_DEVICES=2 python -u main_sample.py \\\n",
    "    --task semantickitti \\\n",
    "    --search_config search_semantickitti_cfg \\\n",
    "    --model_root ./experiments/experiments-pids-new/semantickitti-pids-distribute0 \\\n",
    "    --budget 500"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Architecture Search on ModelNet40 (Sample Stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 python -u main_sample.py \\\n",
    "    --task modelnet40 \\\n",
    "    --search_config search_modelnet40_cfg \\\n",
    "    --model_root ./experiments/experiments-pids-new/modelnet40-pids-distribute0 \\\n",
    "    --budget 500"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Architecture Search on S3DIS (Sample Stage)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Warning: the current setting for S3DIS is not appropriate for NAS because current validation (Area 5) is the same as the outcome of NAS search. If you wish to do NAS on S3DIS, it's better to split a hold-out validation set from the training dataset (Area 1/2/4/6). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 python -u main_sample.py \\\n",
    "    --task s3dis \\\n",
    "    --search_config search_s3dis_cfg \\\n",
    "    --model_root ./experiments/experiments-pids-new/s3dis-pids-distribute0 \\\n",
    "    --budget 500"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Architecture-Flops Pairs (Optional)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flops on SemanticKITTI (Sample Stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!CUDA_VISIBLE_DEVICES=2 python -u main_sample.py \\\n",
    "    --task semantickitti-flops \\\n",
    "    --search_config search_semantickitti_cfg \\\n",
    "    --model_root ./experiments/experiments-pids-new/semantickitti-pids-flops-distribute0 \\\n",
    "    --budget 500"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### S3DIS (Sample Stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 python -u main_sample.py \\\n",
    "    --task s3dis-flops \\\n",
    "    --search_config search_s3dis_cfg \\\n",
    "    --model_root ./experiments/experiments-pids-new/s3dis-pids-flops-distribute0 \\\n",
    "    --budget 500"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ModelNet40 (Sample Stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 python -u main_sample.py \\\n",
    "    --task modelnet40-flops \\\n",
    "    --search_config search_modelnet40_cfg \\\n",
    "    --model_root ./experiments/experiments-pids-new/modelnet40-pids-flops-distribute0 \\\n",
    "    --budget 500"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Dense-Sparse Predictor for accurate accuracy prediction."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A performance predictor is needed to map architectures to their predicted performance. To start with, we have to first train an accurate *FLOPS predictor* that accurately predicts FLOPS. We take SemanticKITTI as an example and it's similar for the rest of the benchmarks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 python train_predictor.py \\\n",
    "    --root_dir ./experiments/experiments-pids-new/ \\\n",
    "    --pattern semantickitti-pids-flops-distribute* \\\n",
    "    --record_name semantickitti-flops-pids.records \\\n",
    "    --task semantickitti-flops \\\n",
    "    --map_fn_name dense-sparse \\\n",
    "    --nn_arch dense-sparse-nn \\\n",
    "    --hparams_json_path ./predictor/hparams/hparams_dense_sparse_nn_semantickitti_flops.json \\\n",
    "    --save_ckpt_path ./predictor/semantickitti_predictors/semantickitti_flops_pred_dense_sparse.pt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the path of `save_ckpt_path` when needed."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, you can proceed with the training of accuracy/mIOU predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 python train_predictor.py --root_dir ./experiments/experiments-pids-new/ \\\n",
    "    --pattern semantickitti-pids-distribute* \\\n",
    "    --record_name semantickitti-pids.records \\\n",
    "    --task semantickitti \\\n",
    "    --map_fn_name dense-sparse \\\n",
    "    --nn_arch dense-sparse-nn \\\n",
    "    --hparams_json_path ./predictor/hparams/hparams_dense_sparse_nn_semantickitti.json \\\n",
    "    --save_ckpt_path ./predictor/acc_prediction/semantickitti_predictive_dense_sparse_nnmodel.pt \\\n",
    "    --pretrain_ckpt_path ./predictor/flops_prediction/semantickitti_predictive_dense_sparse_nnmodel.pt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should change the path when necessary. Note that `--pretrain_ckpt_path` gives you the pretrained predictor on FLOPS prediction tasks (which should be good).\n",
    "\n",
    "If you want to see the cross-validation results on architecture-performance pair mapping (performance prediction), you may try `train_predictor_multisplit.py` to see the full cross-validation result."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that hyperparameters selected for each benchmark can be found in `./predictor/hparams/`. If you switch to a different task, you can check the hyperparameters provided. You can also explore the hyperparameters automatically by setting `single_run=False` in **line 330** of `train_predictor.py`. We provide the pretrained predictors at that time for reference."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search for the best architecture, using trained predictor."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use SemanticKITTI as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!CUDA_VISIBLE_DEVICES=2 python main_search.py --task semantickitti \\\n",
    "    --acc_predictor_ckpt_path ./predictor/acc_prediction/semantickitti-predictive-dense_sparse_nnmodel.pt \\\n",
    "    --flops_predictor_ckpt_path ./predictor/flops_prediction/semantickitti-predictive-dense_sparse_nnmodel.pt \\\n",
    "    --method regularized-ea \\\n",
    "    --dump_json_path ./searched_archs/semantickitti/regularized-ea-dense-sparse-fp0.2-new/results.json \\\n",
    "    --flops_penalty_coef 0.2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note*: `flops_penalty_coef` should be changed according to the predictor training regime. Note that a larger constraint will produce smaller architectures. 0.2-0.5 should be generally fine if the samples are not too biased. Train the top-5 models from scratch will generally give you a good model for final evaluation. In this example, the best architectures are stored in `./searched_archs/semantickitti/regularized-ea-dense-sparse-fp0.2-new/results.json` and you should try the top-5 models to get the best model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, we use regularized evolution as it leads to the best result. You can also try the implementation of RL if you need."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov 24 2022, 14:31:59) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "07007dd0c3dc28847e9efa73310b209a05f1b4ccb58b489d9e033125ed530915"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
